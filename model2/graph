digraph {
	graph [size="30.75,30.75"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	139983975191568 [label="
 (2, 23)" fillcolor=darkolivegreen1]
	139984078714832 [label=SoftmaxBackward0]
	139984078714576 -> 139984078714832
	139984078714576 [label=AddmmBackward0]
	139984078714768 -> 139984078714576
	139983975190896 [label="
 (23)" fillcolor=lightblue]
	139983975190896 -> 139984078714768
	139984078714768 [label=AccumulateGrad]
	139984078715088 -> 139984078714576
	139984078715088 [label=NativeBatchNormBackward0]
	139984078714640 -> 139984078715088
	139984078714640 [label=AddmmBackward0]
	139984078715344 -> 139984078714640
	139984078658736 [label="layer3_0.model.0.bias
 (256)" fillcolor=lightblue]
	139984078658736 -> 139984078715344
	139984078715344 [label=AccumulateGrad]
	139984078715600 -> 139984078714640
	139984078715600 [label=ReshapeAliasBackward0]
	139984078715280 -> 139984078715600
	139984078715280 [label=MulBackward0]
	139984078715792 -> 139984078715280
	139984078715792 [label=MaxPool2DWithIndicesBackward0]
	139984078715920 -> 139984078715792
	139984078715920 [label=NativeBatchNormBackward0]
	139984078715856 -> 139984078715920
	139984078715856 [label=ReluBackward0]
	139984078716240 -> 139984078715856
	139984078716240 [label=ConvolutionBackward0]
	139984078716432 -> 139984078716240
	139984078716432 [label=MulBackward0]
	139984078716624 -> 139984078716432
	139984078716624 [label=MaxPool2DWithIndicesBackward0]
	139984078716816 -> 139984078716624
	139984078716816 [label=NativeBatchNormBackward0]
	139984078716752 -> 139984078716816
	139984078716752 [label=ReluBackward0]
	139983975211280 -> 139984078716752
	139983975211280 [label=ConvolutionBackward1]
	139983975211472 -> 139983975211280
	139983975211472 [label=NativeBatchNormBackward0]
	139983975211664 -> 139983975211472
	139983975211664 [label=ReluBackward0]
	139983975211920 -> 139983975211664
	139983975211920 [label=ConvolutionBackward0]
	139983975212112 -> 139983975211920
	139983975212112 [label=NativeBatchNormBackward0]
	139983975212304 -> 139983975212112
	139983975212304 [label=ReluBackward0]
	139983975212560 -> 139983975212304
	139983975212560 [label=ConvolutionBackward0]
	139983975212752 -> 139983975212560
	139983975212752 [label=MulBackward0]
	139983975212944 -> 139983975212752
	139983975212944 [label=MaxPool2DWithIndicesBackward0]
	139983975213136 -> 139983975212944
	139983975213136 [label=NativeBatchNormBackward0]
	139983975213008 -> 139983975213136
	139983975213008 [label=ReluBackward0]
	139983975213456 -> 139983975213008
	139983975213456 [label=ConvolutionBackward1]
	139983975213648 -> 139983975213456
	139983975213648 [label=NativeBatchNormBackward0]
	139983975213840 -> 139983975213648
	139983975213840 [label=ReluBackward0]
	139983975214096 -> 139983975213840
	139983975214096 [label=ConvolutionBackward0]
	139983975214288 -> 139983975214096
	139983975214288 [label=NativeBatchNormBackward0]
	139983975214480 -> 139983975214288
	139983975214480 [label=ReluBackward0]
	139983975214736 -> 139983975214480
	139983975214736 [label=ConvolutionBackward0]
	139983975214928 -> 139983975214736
	139984078641968 [label="layer1_0.model.0.weight
 (64, 1, 3, 3)" fillcolor=lightblue]
	139984078641968 -> 139983975214928
	139983975214928 [label=AccumulateGrad]
	139983975215056 -> 139983975214736
	139984078641872 [label="layer1_0.model.0.bias
 (64)" fillcolor=lightblue]
	139984078641872 -> 139983975215056
	139983975215056 [label=AccumulateGrad]
	139983975214672 -> 139983975214288
	139984078642160 [label="layer1_0.model.2.weight
 (64)" fillcolor=lightblue]
	139984078642160 -> 139983975214672
	139983975214672 [label=AccumulateGrad]
	139983975214608 -> 139983975214288
	139984078641584 [label="layer1_0.model.2.bias
 (64)" fillcolor=lightblue]
	139984078641584 -> 139983975214608
	139983975214608 [label=AccumulateGrad]
	139983975214416 -> 139983975214096
	139984078642832 [label="layer1_0.model.3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139984078642832 -> 139983975214416
	139983975214416 [label=AccumulateGrad]
	139983975214160 -> 139983975214096
	139984078642736 [label="layer1_0.model.3.bias
 (64)" fillcolor=lightblue]
	139984078642736 -> 139983975214160
	139983975214160 [label=AccumulateGrad]
	139983975214032 -> 139983975213648
	139984078643024 [label="layer1_0.model.5.weight
 (64)" fillcolor=lightblue]
	139984078643024 -> 139983975214032
	139983975214032 [label=AccumulateGrad]
	139983975213968 -> 139983975213648
	139984078642544 [label="layer1_0.model.5.bias
 (64)" fillcolor=lightblue]
	139984078642544 -> 139983975213968
	139983975213968 [label=AccumulateGrad]
	139983975213776 -> 139983975213456
	139984078655856 [label="layer1_0.model.6.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139984078655856 -> 139983975213776
	139983975213776 [label=AccumulateGrad]
	139983975213520 -> 139983975213456
	139984078655760 [label="layer1_0.model.6.bias
 (64)" fillcolor=lightblue]
	139984078655760 -> 139983975213520
	139983975213520 [label=AccumulateGrad]
	139983975213392 -> 139983975213136
	139984078656048 [label="layer1_0.model.8.weight
 (64)" fillcolor=lightblue]
	139984078656048 -> 139983975213392
	139983975213392 [label=AccumulateGrad]
	139983975213328 -> 139983975213136
	139984078655664 [label="layer1_0.model.8.bias
 (64)" fillcolor=lightblue]
	139984078655664 -> 139983975213328
	139983975213328 [label=AccumulateGrad]
	139983975212880 -> 139983975212560
	139984078657296 [label="layer1_1.model.0.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	139984078657296 -> 139983975212880
	139983975212880 [label=AccumulateGrad]
	139983975212624 -> 139983975212560
	139986230131312 [label="layer1_1.model.0.bias
 (128)" fillcolor=lightblue]
	139986230131312 -> 139983975212624
	139983975212624 [label=AccumulateGrad]
	139983975212496 -> 139983975212112
	139984078875920 [label="layer1_1.model.2.weight
 (128)" fillcolor=lightblue]
	139984078875920 -> 139983975212496
	139983975212496 [label=AccumulateGrad]
	139983975212432 -> 139983975212112
	139984078875632 [label="layer1_1.model.2.bias
 (128)" fillcolor=lightblue]
	139984078875632 -> 139983975212432
	139983975212432 [label=AccumulateGrad]
	139983975212240 -> 139983975211920
	139984078874672 [label="layer1_1.model.3.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	139984078874672 -> 139983975212240
	139983975212240 [label=AccumulateGrad]
	139983975211984 -> 139983975211920
	139984078874288 [label="layer1_1.model.3.bias
 (128)" fillcolor=lightblue]
	139984078874288 -> 139983975211984
	139983975211984 [label=AccumulateGrad]
	139983975211856 -> 139983975211472
	139984078873616 [label="layer1_1.model.5.weight
 (128)" fillcolor=lightblue]
	139984078873616 -> 139983975211856
	139983975211856 [label=AccumulateGrad]
	139983975211792 -> 139983975211472
	139984078874960 [label="layer1_1.model.5.bias
 (128)" fillcolor=lightblue]
	139984078874960 -> 139983975211792
	139983975211792 [label=AccumulateGrad]
	139983975211600 -> 139983975211280
	139984078831984 [label="layer1_1.model.6.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	139984078831984 -> 139983975211600
	139983975211600 [label=AccumulateGrad]
	139983975211344 -> 139983975211280
	139984078831792 [label="layer1_1.model.6.bias
 (128)" fillcolor=lightblue]
	139984078831792 -> 139983975211344
	139983975211344 [label=AccumulateGrad]
	139983975211216 -> 139984078716816
	139984078833040 [label="layer1_1.model.8.weight
 (128)" fillcolor=lightblue]
	139984078833040 -> 139983975211216
	139983975211216 [label=AccumulateGrad]
	139983975211152 -> 139984078716816
	139984078832464 [label="layer1_1.model.8.bias
 (128)" fillcolor=lightblue]
	139984078832464 -> 139983975211152
	139983975211152 [label=AccumulateGrad]
	139984078716560 -> 139984078716240
	139984078658256 [label="layer2_0.model.0.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	139984078658256 -> 139984078716560
	139984078716560 [label=AccumulateGrad]
	139984078716304 -> 139984078716240
	139984078658160 [label="layer2_0.model.0.bias
 (256)" fillcolor=lightblue]
	139984078658160 -> 139984078716304
	139984078716304 [label=AccumulateGrad]
	139984078716176 -> 139984078715920
	139984078658448 [label="layer2_0.model.2.weight
 (256)" fillcolor=lightblue]
	139984078658448 -> 139984078716176
	139984078716176 [label=AccumulateGrad]
	139984078716112 -> 139984078715920
	139984078657488 [label="layer2_0.model.2.bias
 (256)" fillcolor=lightblue]
	139984078657488 -> 139984078716112
	139984078716112 [label=AccumulateGrad]
	139984078715536 -> 139984078714640
	139984078715536 [label=TBackward0]
	139984078715728 -> 139984078715536
	139984078659216 [label="layer3_0.model.0.weight
 (256, 6400)" fillcolor=lightblue]
	139984078659216 -> 139984078715728
	139984078715728 [label=AccumulateGrad]
	139984078715152 -> 139984078715088
	139984078659312 [label="layer3_0.model.1.weight
 (256)" fillcolor=lightblue]
	139984078659312 -> 139984078715152
	139984078715152 [label=AccumulateGrad]
	139984078715216 -> 139984078715088
	139984078659408 [label="layer3_0.model.1.bias
 (256)" fillcolor=lightblue]
	139984078659408 -> 139984078715216
	139984078715216 [label=AccumulateGrad]
	139984078715024 -> 139984078714576
	139984078715024 [label=TBackward0]
	139984078715408 -> 139984078715024
	139983975191088 [label="
 (23, 256)" fillcolor=lightblue]
	139983975191088 -> 139984078715408
	139984078715408 [label=AccumulateGrad]
	139984078714832 -> 139983975191568
}
